{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\n# imports related to model building and evaluation\nfrom pyspark.ml import Pipeline, Estimator, Transformer, Model, PipelineModel\nimport pyspark.ml.feature as MFT\nimport pyspark.ml.functions as MF\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n# first attempt to build a model (whole code given)\nimport seaborn as sns\ndf = sns.load_dataset('iris')\n\n# binary classification\ndf_binary = df.assign(species=df['species'].where(df['species']=='virginica', 'not virginica'))\ndf_binary = spark.createDataFrame(df_binary)\n\n# pack the features into a vector (this is a transformer)\n# we do not use all features to allow some room for model tuning\n# feature_assembler = MFT.VectorAssembler(inputCols=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], outputCol='features')\nfeature_assembler = MFT.VectorAssembler(inputCols=['sepal_width', 'petal_width'], outputCol='features')\n\n# create a min max scaler (this is an estimator)\nminMax_scaler = MFT.MinMaxScaler(min=0., max=1., inputCol='features', outputCol='features_scaled')\n\n# string indexer (this is a transformer)\nlabels = [\"not virginica\", \"virginica\"]\nfromlabelsModel = MFT.StringIndexerModel.from_labels(labels,\n                                                     inputCol=\"species\", outputCol=\"species_indexed\",\n                                                     handleInvalid=\"error\")\n\n# create a binomial logistic regression model (this is an estimator)\nlr = LogisticRegression(featuresCol='features_scaled', labelCol='species_indexed', predictionCol='prediction')\n\n# build the pipeline\npipeline = Pipeline(stages=[feature_assembler, minMax_scaler, fromlabelsModel, lr])\n\n# cache the dataset to ensure deterministic behaviour and ensure fast model fitting\ndf_binary.cache()\ntrain, test = df_binary.randomSplit([0.2, 0.8], seed=8)\n\n# fit the model\npipeline_model = pipeline.fit(train)\n\n# apply the model to the test set\nresults = pipeline_model.transform(test)\nresults = MFT.IndexToString(inputCol='prediction', outputCol='species_predicted', labels=labels).transform(results)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"56fccb84-f4ce-4c16-b88a-c79aec2629a9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["results.select('prediction','species_indexed','species','species_predicted').show(100,truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ee39bdb0-a5da-458d-b4ee-7c21fc358537","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+---------------+-------------+-----------------+\n|prediction|species_indexed|species      |species_predicted|\n+----------+---------------+-------------+-----------------+\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|1.0       |0.0            |not virginica|virginica        |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|1.0       |0.0            |not virginica|virginica        |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|1.0       |0.0            |not virginica|virginica        |\n|0.0       |0.0            |not virginica|not virginica    |\n|1.0       |1.0            |virginica    |virginica        |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|0.0       |0.0            |not virginica|not virginica    |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n|1.0       |1.0            |virginica    |virginica        |\n+----------+---------------+-------------+-----------------+\nonly showing top 100 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["results.groupBy('species').pivot('species_predicted').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"72f901b9-f567-4041-b8fe-084fad352892","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+-------------+---------+\n|      species|not virginica|virginica|\n+-------------+-------------+---------+\n|    virginica|            2|       38|\n|not virginica|           80|        3|\n+-------------+-------------+---------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["confusion_matrix = (results.groupby('species').pivot('species_predicted').count().toPandas()\n                    .set_index('species').sort_index(axis='index', ascending=False).sort_index(axis='columns', ascending=False)\n                    .fillna(0).astype(int)\n                    )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"705ffdbc-8a8a-4e94-b9fb-8b712f3dcc63","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ax = sns.heatmap(confusion_matrix, cmap='Blues', annot=True, cbar=False)\nax.set_xlabel('Prediction')\nax.set_ylabel('True value')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f2cf864d-4f55-4956-ac8a-a5b26b3c9bae","inputWidgets":{},"title":""}},"outputs":[{"output_type":"execute_result","metadata":{},"execution_count":11,"output_type":"execute_result","data":{"text/plain":["Text(50.72222222222221, 0.5, 'True value')"]}},{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"}}],"execution_count":0},{"cell_type":"code","source":["lr_model = pipeline_model.stages[-1]\nmetrics = lr_model.evaluate(results.select('features_scaled', 'species_indexed'))\n\nprint(f'Recall, sensitivity or true positive rate {metrics.recallByLabel[1]:.4f}')\nprint(f'Precision or positive predictive value {metrics.precisionByLabel[1]:.4f}')\nprint(f'Specificity or true negative rate {1-metrics.falsePositiveRateByLabel[1]:.4f}')\nprint(f'False positive rate or (1 - specificity) {metrics.falsePositiveRateByLabel[1]:.4f}')\n# Recall, sensitivity or true positive rate 0.9167\n# Precision or positive predictive value 0.8919\n# Specificity or true negative rate 0.9506\n# False positive rate or (1 - specificity) 0.0494\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a6795d96-1c14-4152-9d46-8461601e0072","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Recall, sensitivity or true positive rate 0.9500\nPrecision or positive predictive value 0.9268\nSpecificity or true negative rate 0.9639\nFalse positive rate or (1 - specificity) 0.0361\n"]}],"execution_count":0},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(labelCol='species_indexed', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\nareaUnderROC = evaluator.evaluate(results.select('species_indexed', 'rawPrediction'))\n\nprint(f'The area under the ROC curve for the test set is {areaUnderROC:.4f}')\n# The area under the ROC curve for the test set is 0.9933"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7bac2c6b-64ac-4ac2-91a1-37c724cf205d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["The area under the ROC curve for the test set is 0.9967\n"]}],"execution_count":0},{"cell_type":"code","source":["# cross validation and fine tuning\n# complete code, incuding cross-validation\nimport seaborn as sns\ndf = sns.load_dataset('iris')\n\n# binary classification\ndf_binary = df.assign(species=df['species'].where(df['species']=='virginica', 'not virginica'))\ndf_binary = spark.createDataFrame(df_binary)\n\n# cache the dataset to ensure deterministic behaviour and ensure fast model fitting\ndf_binary.cache()\ntrain, test = df_binary.randomSplit([0.6, 0.4], seed=8)\n\n# pack the features into a vector (this is a transformer)\nfeature_assembler = MFT.VectorAssembler(inputCols=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], outputCol='features')\n\n# create a min max scaler (this is an estimator)\nminMax_scaler = MFT.MinMaxScaler(min=0., max=1., inputCol='features', outputCol='features_scaled')\n\n# string indexer (this is a transformer)\nlabels = [\"not virginica\", \"virginica\"]\nfromlabelsModel = MFT.StringIndexerModel.from_labels(labels,\n                                                     inputCol=\"species\", outputCol=\"species_indexed\",\n                                                     handleInvalid=\"error\")\n\n# create a binomial logistic regression model (this is an estimator)\nlr = LogisticRegression(featuresCol='features_scaled', labelCol='species_indexed', predictionCol='prediction')\n\n# build the pipeline\npipeline = Pipeline(stages=[feature_assembler, minMax_scaler, fromlabelsModel, lr])\n\n# build the parameter map (grid)\nfrom itertools import combinations, chain\nfrom pprint import pprint\nfrom time import time\ncols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\ncols_combinations = list(chain(combinations(cols, 2), combinations(cols, 3), combinations(cols, 4)))\npprint(cols_combinations)\n# [('sepal_length', 'sepal_width'),\n#  ('sepal_length', 'petal_length'),\n#  ('sepal_length', 'petal_width'),\n#  ('sepal_width', 'petal_length'),\n#  ('sepal_width', 'petal_width'),\n#  ('petal_length', 'petal_width'),\n#  ('sepal_length', 'sepal_width', 'petal_length'),\n#  ('sepal_length', 'sepal_width', 'petal_width'),\n#  ('sepal_length', 'petal_length', 'petal_width'),\n#  ('sepal_width', 'petal_length', 'petal_width'),\n#  ('sepal_length', 'sepal_width', 'petal_length', 'petal_width')]\nparam_grid = (ParamGridBuilder()\n              .addGrid(lr.elasticNetParam, [0., 0.5, 1.])\n              .addGrid(lr.regParam, [0., 0.1, 1., 2., 5.])\n              .addGrid(feature_assembler.inputCols, cols_combinations)\n              .build())\n\n# evaluate the model performance\nevaluator = BinaryClassificationEvaluator(labelCol='species_indexed', rawPredictionCol='rawPrediction', metricName='areaUnderROC')\n\n# setup the cross validation estimator\ncv = CrossValidator(estimator=pipeline,\n                    estimatorParamMaps=param_grid,\n                    evaluator=evaluator,\n                    numFolds=4,\n                    seed=8,\n                    collectSubModels=True)\n\n# fit the model using cross-validation and grid search\nstart_time = time()\ncv_model = cv.fit(train)\n\nprint(f'Hyper-parameter tuning using 4-fold validation took {time()-start_time: 0.2f} sec')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5ca294c6-d307-4f6b-8628-190df8bf14e7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["[('sepal_length', 'sepal_width'),\n ('sepal_length', 'petal_length'),\n ('sepal_length', 'petal_width'),\n ('sepal_width', 'petal_length'),\n ('sepal_width', 'petal_width'),\n ('petal_length', 'petal_width'),\n ('sepal_length', 'sepal_width', 'petal_length'),\n ('sepal_length', 'sepal_width', 'petal_width'),\n ('sepal_length', 'petal_length', 'petal_width'),\n ('sepal_width', 'petal_length', 'petal_width'),\n ('sepal_length', 'sepal_width', 'petal_length', 'petal_width')]\nHyper-parameter tuning using 4-fold validation took  4483.65 sec\n"]}],"execution_count":0},{"cell_type":"code","source":["# obtain the best model and the optimised hyper-parameters\nbest_model = cv_model.bestModel\nprint(f'features maintained in the best model {best_model.stages[0].getInputCols()}')\nprint(f'elastic net parameter in the best model {best_model.stages[-1].getElasticNetParam()}')\nprint(f'regularization parameter in the best model {best_model.stages[-1].getRegParam()}')\n# features maintained in the best model ['sepal_width', 'petal_width']\n# elastic net parameter in the best model 0.0\n# regularization parameter in the best model 0.0\n\n# apply the model to the training set\nresults = best_model.transform(train)\nresults = MFT.IndexToString(inputCol='prediction', outputCol='species_predicted', labels=labels).transform(results)\n\n# compute the confusion matrix manually (for the training set)\nconfusion_matrix = (results.groupby('species').pivot('species_predicted').count().toPandas()\n                    .set_index('species').sort_index(axis='index', ascending=False).sort_index(axis='columns', ascending=False)\n                    .fillna(0).astype(int)\n                    )\nprint(confusion_matrix)\n#                virginica  not virginica\n# species  \n# \n# # obtain the best model and the optimised hyper-parameters\nbest_model = cv_model.bestModel\nprint(f'features maintained in the best model {best_model.stages[0].getInputCols()}')\nprint(f'elastic net parameter in the best model {best_model.stages[-1].getElasticNetParam()}')\nprint(f'regularization parameter in the best model {best_model.stages[-1].getRegParam()}')\n# features maintained in the best model ['sepal_width', 'petal_width']\n# elastic net parameter in the best model 0.0\n# regularization parameter in the best model 0.0\n\n# apply the model to the training set\nresults = best_model.transform(train)\nresults = MFT.IndexToString(inputCol='prediction', outputCol='species_predicted', labels=labels).transform(results)\n\n# compute the confusion matrix manually (for the training set)\nconfusion_matrix = (results.groupby('species').pivot('species_predicted').count().toPandas()\n                    .set_index('species').sort_index(axis='index', ascending=False).sort_index(axis='columns', ascending=False)\n                    .fillna(0).astype(int)\n                    )\nprint(confusion_matrix)\n# retrieve the coefficients\nresults = best_model.transform(train)\nresults = MFT.IndexToString(inputCol='prediction', outputCol='species_predicted', labels=labels).transform(results)\ncoef_names = ['intercept'] + [x['name'] for x in results.schema['features'].metadata['ml_attr']['attrs']['numeric']]\ncoef_values = [best_model.stages[-1].intercept] + list(best_model.stages[-1].coefficients)\ncoefs = pd.Series(coef_values, index=coef_names)\n\nprint(coefs)\nresults = results.select('features_scaled', 'species', 'species_predicted')\nresults = results.withColumn('sepal_width_scaled', MF.vector_to_array(F.col('features_scaled'))[0])\nresults = results.withColumn('petal_width_scaled', MF.vector_to_array(F.col('features_scaled'))[1])\nresults_pd = results.select('sepal_width_scaled', 'petal_width_scaled', 'species', 'species_predicted').toPandas()\n\nax = sns.scatterplot(data=results_pd, x='sepal_width_scaled', y='petal_width_scaled', hue='species')\nxs = np.linspace(results_pd['sepal_width_scaled'].min(), results_pd['sepal_width_scaled'].max(), 3)\nys = (-coefs['intercept'] - coefs['sepal_width']*xs)/coefs['petal_width']\nsns.lineplot(x=xs, y=ys, ax=ax)\nax.lines[0].set_linestyle(\"--\")\nax.lines[0].set_color(\"k\")\nax.set_xlabel('sepal width (scaled)')\nax.set_ylabel('petal width (scaled)')                             "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"08847c43-463d-4bc9-8595-f919cfc535ad","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# multinomial logistic regression\nimport seaborn as sns\ndf = sns.load_dataset('iris')\n\n# binary classification\ndf_multinomial = spark.createDataFrame(df)\n\n# pack the features into a vector (this is a transformer)\nfeature_assembler = MFT.VectorAssembler(inputCols=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], outputCol='features')\n\n# create a min max scaler (this is an estimator)\nminMax_scaler = MFT.MinMaxScaler(min=0., max=1., inputCol='features', outputCol='features_scaled')\n\n# string indexer (this is a transformer)\nlabels = ['setosa', 'versicolor', 'virginica']\nfromlabelsModel = MFT.StringIndexerModel.from_labels(labels,\n                                                     inputCol=\"species\", outputCol=\"species_indexed\",\n                                                     handleInvalid=\"error\")\n\n# create a binomial logistic regression model (this is an estimator)\nlr = LogisticRegression(featuresCol='features_scaled', labelCol='species_indexed', predictionCol='prediction')\n\n# build the pipeline\npipeline = Pipeline(stages=[feature_assembler, minMax_scaler, fromlabelsModel, lr])\n\n# cache the dataset to ensure deterministic behaviour and ensure fast model fitting\ndf_multinomial.cache()\ntrain, test = df_multinomial.randomSplit([0.8, 0.2], seed=8)\n\n# fit the model\npipeline_model = pipeline.fit(train)\n\n# apply the model to the test set\nresults = pipeline_model.transform(test)\nresults = MFT.IndexToString(inputCol='prediction', outputCol='species_predicted', labels=labels).transform(results)\n\n# compute the confusion matrix manually (for the test set)\nconfusion_matrix = (results.groupby('species').pivot('species_predicted').count().toPandas()\n                    .set_index('species').sort_index(axis='index', ascending=False).sort_index(axis='columns', ascending=False)\n                    .fillna(0).astype(int)\n                    )\nprint(confusion_matrix)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"78f23b9f-df97-4491-8140-63989fbd8412","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"LogsticRegression过程简洁","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
